{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are all features covered in X_train: True\n",
      "Features in features_tot but not in X_train: set()\n",
      "Features in X_train but not in features_tot: set()\n",
      "Selected 83 features with |correlation| > 0.003\n",
      "Training the final model with optimal hyperparameters on the entire training dataset...\n",
      "Final model training completed.\n",
      "predictions on the test set...\n",
      "Predictions saved to submission.csv\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.pipeline import Pipeline  \n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "pd.pandas.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "def make_predictions(test_fname, predictions_fname):\n",
    "    df = pd.read_csv(\"train.csv\")\n",
    "    df.head(90)\n",
    "    print(df.shape)\n",
    "    X_test = pd.read_csv(test_fname)\n",
    "    # df.head(20)\n",
    "\n",
    "\n",
    "    features_ordinal = ['FarmClassification', 'NumberGreenHouses']\n",
    "    features_year = ['TaxOverdueYear', 'ValuationYear', 'FieldEstablishedYear']\n",
    "\n",
    "    features_categorical = []\n",
    "    for feature in df.columns:\n",
    "        if (df[feature].nunique() < 50) and (feature not in (features_ordinal)) and (feature not in features_year) and(feature != 'Target'):\n",
    "            features_categorical.append(feature)\n",
    "\n",
    "    df['TaxOverdueYear'].fillna('missing', inplace=True)\n",
    "    df['ValuationYear'] = 2020 - df['ValuationYear']\n",
    "    df['FieldEstablishedYear'] = 2020 - df['FieldEstablishedYear']\n",
    "\n",
    "    features_categorical.append('TaxOverdueYear')\n",
    "\n",
    "    features_numerical = []\n",
    "    for feature in df.columns:\n",
    "        if (df[feature].nunique() >= 50) and (feature not in (features_ordinal)) and (feature not in features_year) and (feature != 'Target'):\n",
    "            features_numerical.append(feature)\n",
    "    features_numerical.append('ValuationYear')\n",
    "    features_numerical.append('FieldEstablishedYear')\n",
    "    features = features_numerical + features_categorical + features_ordinal\n",
    "    print(len(features))\n",
    "    print(len(features_categorical))\n",
    "\n",
    "    features_drop = ['FarmingCommunityId', 'AgriculturalPostalZone', 'OtherZoningCode', 'AgricultureZoningCode']\n",
    "    features = [feature for feature in features if feature not in features_drop]\n",
    "    df = df.drop(features_drop, axis = 1)\n",
    "    features_categorical = [feature for feature in features_categorical if feature not in features_drop]\n",
    "    features_numerical = [feature for feature in features_numerical if feature not in features_drop]\n",
    "\n",
    "\n",
    "    features_num_not_cat = ['WaterAccessPointsCalc', 'WaterAccessPoints', 'StorageAndFacilityCount', 'MainIrrigationSystemCount', 'FarmingUnitCount']\n",
    "\n",
    "    features_categorical = [feature for feature in features_categorical if feature not in features_num_not_cat]\n",
    "\n",
    "    features_numerical.extend(features_num_not_cat)\n",
    "    print(len(features))\n",
    "    features_cat_nan = []\n",
    "    features_cat_drop = []\n",
    "    for feature in features_categorical:\n",
    "        num_nans = df[feature].isnull().mean()\n",
    "        if num_nans > 0.90:\n",
    "            features_cat_nan.append(feature)\n",
    "\n",
    "    features_drop = features_cat_nan\n",
    "    features = [feature for feature in features if feature not in features_drop]\n",
    "    df = df.drop(features_drop, axis = 1)\n",
    "    features_categorical = [feature for feature in features_categorical if feature not in features_drop]\n",
    "    features_numerical = [feature for feature in features_numerical if feature not in features_drop]\n",
    "    print(len(features))\n",
    "    features_num_nan = []\n",
    "    features_num_drop = []\n",
    "    for feature in features_numerical:\n",
    "        num_nans = df[feature].isnull().mean()\n",
    "        if num_nans > 0.90:\n",
    "            features_num_nan.append(feature)\n",
    "\n",
    "\n",
    "    features_drop = features_num_nan\n",
    "    features = [feature for feature in features if feature not in features_drop]\n",
    "    df = df.drop(features_drop, axis = 1)\n",
    "    features_categorical = [feature for feature in features_categorical if feature not in features_drop]\n",
    "    features_numerical = [feature for feature in features_numerical if feature not in features_drop]\n",
    "    print(len(features))\n",
    "    X_test = X_test[features]\n",
    "    print(df.shape)\n",
    "    columns_not_in_features = set(df.columns) - set(features)\n",
    "\n",
    "    #check if the columns are mismatching\n",
    "    print(\"Columns in df but not in features:\", columns_not_in_features)\n",
    "    print(\"Columns in df:\", list(df.columns))\n",
    "    print(len(features_categorical))\n",
    "    print(len(features_numerical))\n",
    "    print(len(features_ordinal))\n",
    "    print(df.shape)\n",
    "\n",
    "    for feature in features_categorical:\n",
    "        print(f\"{feature}: \", df[feature].nunique())\n",
    "\n",
    "    print(df.shape)\n",
    "    print(X_test.shape)\n",
    "\n",
    "\n",
    "    df = pd.get_dummies(df, columns=features_categorical, drop_first=True)\n",
    "    X_test = pd.get_dummies(X_test, columns=features_categorical, drop_first=True)\n",
    "    X_train = df.drop(columns=['Target'])\n",
    "\n",
    "\n",
    "    x_test_columns = set(X_test.columns)\n",
    "    x_train_columns_set = set(X_train.columns)\n",
    "\n",
    "    all_features_covered = x_test_columns == x_train_columns_set\n",
    "    print(f'Features of C_train and X_test are same: {all_features_covered}')\n",
    "\n",
    "    features_only_in_features_tot = x_test_columns - x_train_columns_set\n",
    "    features_only_in_x_train = x_train_columns_set - x_test_columns\n",
    "\n",
    "    print(\"Features in x_test but not in X_train:\", features_only_in_features_tot)\n",
    "    print(\"Features in X_train but not in x_test:\", features_only_in_x_train)\n",
    "\n",
    "\n",
    "    X_test_columns = X_test.columns\n",
    "    X_train = X_train.reindex(columns=X_test.columns, fill_value=0)\n",
    "\n",
    "    y_train = df['Target']\n",
    "\n",
    "\n",
    "\n",
    "    threshold = 0.003\n",
    "    X_train_new = X_train.drop('UID', axis=1).copy()\n",
    "    X_test_new = X_test.drop('UID', axis=1).copy()\n",
    "\n",
    "    features_categorical = [feature for feature in X_train_new.columns if feature not in features_numerical]\n",
    "    numerical_features = [feature for feature in features_numerical if feature in X_train_new.columns]\n",
    "    categorical_features = [feature for feature in features_categorical if feature in X_train_new.columns]\n",
    "\n",
    "    features_tot = numerical_features + categorical_features\n",
    "    features_tot_set = set(features_tot)\n",
    "    x_train_columns_set = set(X_train_new.columns)\n",
    "\n",
    "    all_features_covered = features_tot_set == x_train_columns_set\n",
    "    print(f'Are all features covered in X_train: {all_features_covered}')\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "\n",
    "    features_only_in_features_tot = features_tot_set - x_train_columns_set\n",
    "    features_only_in_x_train = x_train_columns_set - features_tot_set\n",
    "    print(\"Features in features_tot but not in X_train:\", features_only_in_features_tot)\n",
    "    print(\"Features in X_train but not in features_tot:\", features_only_in_x_train)\n",
    "\n",
    "    df_combined = X_train_new.copy()\n",
    "    df_combined['Target'] = y_train_encoded\n",
    "\n",
    "    correlation_matrix = df_combined.corr()\n",
    "\n",
    "    feature_correlations = correlation_matrix['Target'].drop('Target')\n",
    "\n",
    "    if threshold == 0:\n",
    "        selected_features = feature_correlations.index.tolist()\n",
    "    else:\n",
    "        selected_features = feature_correlations[feature_correlations.abs() > threshold].index.tolist()\n",
    "\n",
    "    print(f\"Selected {len(selected_features)} features with |correlation| > {threshold}\")\n",
    "    X_train_threshold = X_train_new[selected_features].copy()\n",
    "    X_test_threshold = X_test_new[selected_features].copy()\n",
    "\n",
    "    numerical_features_threshold = [feature for feature in numerical_features if feature in selected_features]\n",
    "    categorical_features_threshold = [feature for feature in categorical_features if feature in selected_features]\n",
    "\n",
    "    numerical_transformer = SimpleImputer(strategy='median')\n",
    "    categorical_transformer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[('num', numerical_transformer, numerical_features_threshold),('cat', categorical_transformer, categorical_features_threshold)])\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('resampler', SMOTEENN(random_state=12)),\n",
    "    ('classifier', RandomForestClassifier(random_state=12, n_jobs=-1, class_weight='balanced', n_estimators=1000, min_samples_split=2, min_samples_leaf=4, max_features='log2', max_depth=None))\n",
    "    ])\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "    print(\"training the final model on the entire training dataset\")\n",
    "    pipeline.fit(X_train_threshold, y_train_encoded)\n",
    "    print(\"final training done\")\n",
    "\n",
    "    print(\"predictions on the test set\")\n",
    "    predictions = pipeline.predict(X_test_threshold)\n",
    "\n",
    "    predicted_labels = label_encoder.inverse_transform(predictions)\n",
    "\n",
    "    submission_df = pd.DataFrame({'UID': X_test['UID'],'Target': predicted_labels})\n",
    "\n",
    "    submission_df.to_csv(predictions_fname, index=False)\n",
    "    print(\"predictions saved to submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--train-file\", type=str, help='file path of train.csv')\n",
    "    parser.add_argument(\"--test-file\", type=str, help='file path of test.csv')\n",
    "    parser.add_argument(\"--predictions-file\", type=str, help='save path of predictions')\n",
    "    args = parser.parse_args()\n",
    "    make_predictions(args.test_file, args.predictions_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
